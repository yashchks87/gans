{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import glob\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from tensorflow import keras\n",
    "import sys\n",
    "import PIL\n",
    "import os\n",
    "import tensorflow.keras.backend as K\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Conv2D, Dropout\n",
    "from keras.layers import BatchNormalization, Flatten\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Reshape # new! \n",
    "from keras.layers import Conv2DTranspose, UpSampling2D # new! \n",
    "from keras.optimizers import RMSprop # new!\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('../data/dogs_cats/train/*.jpg')\n",
    "cat_files = [x for x in files if 'cat' in x.split('/')[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = Image.open(cat_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discriminator():\n",
    "    input_layer = Input((112, 112, 3))\n",
    "    re_layer = keras.applications.ResNet50(include_top=False,\n",
    "                                           weights = 'imagenet',\n",
    "                                           input_shape = (112, 112, 3),\n",
    "                                           pooling = 'avg')(input_layer)\n",
    "    final_layer = Dense(1, activation='sigmoid')(re_layer)\n",
    "    model = Model(inputs=input_layer, outputs = final_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-07 18:16:33.113454: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-07 18:16:33.158553: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-07 18:16:33.158959: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-07 18:16:33.160127: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-07 18:16:33.162057: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-07 18:16:33.162452: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-07 18:16:33.162808: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-07 18:16:33.978091: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-07 18:16:33.978522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-07 18:16:33.978896: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-07 18:16:33.979217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14636 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:1b.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "discriminator = get_discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 112, 112, 3)]     0         \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 2048)              23587712  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 2049      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,589,761\n",
      "Trainable params: 23,536,641\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.compile(\n",
    "    loss = keras.losses.BinaryCrossentropy(),\n",
    "    optimizer = keras.optimizers.SGD(),\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dimensions = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(latent_dim=z_dimensions, \n",
    "                    depth=64, p=0.4):\n",
    "    \n",
    "    # Define inputs\n",
    "    noise = Input((latent_dim,))\n",
    "    \n",
    "    # First dense layer\n",
    "    dense1 = Dense(7*7*depth)(noise)\n",
    "    dense1 = BatchNormalization(momentum=0.9)(dense1) # default momentum for moving average is 0.99\n",
    "    dense1 = Activation(activation='relu')(dense1)\n",
    "    dense1 = Reshape((7,7,depth))(dense1)\n",
    "    dense1 = Dropout(p)(dense1)\n",
    "    \n",
    "    # De-Convolutional layers\n",
    "    conv1 = UpSampling2D()(dense1)\n",
    "    conv1 = Conv2DTranspose(int(depth/2), \n",
    "                            kernel_size=5, padding='same', \n",
    "                            activation=None,)(conv1)\n",
    "    conv1 = BatchNormalization(momentum=0.9)(conv1)\n",
    "    conv1 = Activation(activation='relu')(conv1)\n",
    "    \n",
    "    conv2 = UpSampling2D()(conv1)\n",
    "    conv2 = Conv2DTranspose(int(depth/4), \n",
    "                            kernel_size=5, padding='same', \n",
    "                            activation=None,)(conv2)\n",
    "    conv2 = BatchNormalization(momentum=0.9)(conv2)\n",
    "    conv2 = Activation(activation='relu')(conv2)\n",
    "\n",
    "    conv3 = UpSampling2D((4, 4))(conv2)\n",
    "    conv3 = Conv2DTranspose(int(depth/4), \n",
    "                            kernel_size=5, padding='same', \n",
    "                            activation=None,)(conv3)\n",
    "    conv3 = BatchNormalization(momentum=0.9)(conv3)\n",
    "    conv3 = Activation(activation='relu')(conv3)\n",
    "    \n",
    "    conv4 = Conv2DTranspose(int(depth/8), \n",
    "                            kernel_size=5, padding='same', \n",
    "                            activation=None,)(conv3)\n",
    "    conv4 = BatchNormalization(momentum=0.9)(conv4)\n",
    "    conv4 = Activation(activation='relu')(conv4)\n",
    "\n",
    "    # Output layer\n",
    "    image = Conv2D(3, kernel_size=1, padding='valid', \n",
    "                   activation='sigmoid')(conv4)\n",
    "\n",
    "    # Model definition    \n",
    "    model = Model(inputs=noise, outputs=image)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = build_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 32)]              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3136)              103488    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 3136)             12544     \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 3136)              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2D  (None, 14, 14, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 14, 14, 32)       51232     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 14, 14, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 14, 14, 32)        0         \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSampling  (None, 28, 28, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 28, 28, 16)       12816     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 28, 28, 16)       64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 28, 28, 16)        0         \n",
      "                                                                 \n",
      " up_sampling2d_2 (UpSampling  (None, 112, 112, 16)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 112, 112, 16)     6416      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 112, 112, 16)     64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 112, 112, 16)      0         \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 112, 112, 8)      3208      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 112, 112, 8)      32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 112, 112, 8)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 112, 112, 3)       27        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 190,019\n",
      "Trainable params: 183,603\n",
      "Non-trainable params: 6,416\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = Input(shape=(z_dimensions,))\n",
    "img = generator(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = discriminator(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_model = Model(z, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_model.compile(loss='binary_crossentropy', \n",
    "                          optimizer=keras.optimizers.SGD(), \n",
    "                          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'model')>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 32)]              0         \n",
      "                                                                 \n",
      " model_1 (Functional)        (None, 112, 112, 3)       190019    \n",
      "                                                                 \n",
      " model (Functional)          (None, 1)                 23589761  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,779,780\n",
      "Trainable params: 183,603\n",
      "Non-trainable params: 23,596,177\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "adversarial_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs = 200, batch = 32, z_dim = z_dimensions):\n",
    "    d_metrics, a_metrics = [], []\n",
    "    \n",
    "    running_d_loss = 0\n",
    "    running_d_acc = 0\n",
    "    running_a_loss = 0\n",
    "    running_a_acc = 0\n",
    "    current_batch_start = 0\n",
    "    count = 0\n",
    "    for i in range(epochs):\n",
    "        real_imgs = np.zeros(shape=(batch, 112, 112, 3))\n",
    "        real_img_start = 0\n",
    "        for x_ in range(current_batch_start, current_batch_start + batch):\n",
    "            img = cv2.imread(cat_files[x_])\n",
    "            img = cv2.resize(img, (112, 112))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = img / 255\n",
    "            real_imgs[real_img_start] = img\n",
    "            real_img_start += 1\n",
    "        # break\n",
    "\n",
    "        # Generate random images\n",
    "        random_latent = np.random.uniform(\n",
    "                0, 1.0, size=(batch, z_dimensions)\n",
    "            )\n",
    "        fake_imgs = generator.predict(\n",
    "            random_latent, verbose = 1\n",
    "        )\n",
    "        x = np.concatenate((real_imgs, fake_imgs))\n",
    "        # return real_imgs\n",
    "\n",
    "        y = np.ones([2 * batch, 1])\n",
    "        y[batch:, :] 0\n",
    "\n",
    "        d_metrics.append(\n",
    "            discriminator.train_on_batch(x, y)\n",
    "        )\n",
    "\n",
    "        running_d_loss += d_metrics[-1][0]\n",
    "        running_d_acc += d_metrics[-1][1]\n",
    "\n",
    "        noise = np.random.uniform(\n",
    "            \n",
    "        )\n",
    "        break\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-07 18:20:17.127333: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-07 18:20:17.999625: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    }
   ],
   "source": [
    "data = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 112, 112, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.ones([32 * 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[32:, :] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ship_segmentation",
   "language": "python",
   "name": "ship_segmentation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
